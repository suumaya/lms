<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Codeanywhere adventures - Getting started with browser based development in containers (part 1)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/N5F8i1B0ELc/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/w_-D18LhPN8/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html</id><updated>2021-09-29T05:00:00Z</updated><content type="html">Are you ready for some amazing, easy to use, developer tooling that requires not a single tooling installation and no configuration?  That's what the team at are promising us with their cloud IDE when I stumbled on their website last week. They "...don't require you to engage in complex installations and configuration setups. Simply access our in-browser IDE for everything you need to build amazing websites in a productive and more developer-friendly way." Not only that, it's a browser-based developer IDE that ties your coding directly to a pipeline of deployment using containers with immediate friendly tips to access for testing your projects. I'm thinking we need to look at this a bit closer and wanted to share my adventures here with you, starting with part one, getting started. Full disclosure, I know some of the developers behind this product. Initially, I was using the free account they offer that you can spin from the button on the front page, but they reached out and gave me a bit more freedom to explore their offerings. Be sure to , they are a friendly bunch of developers and very happy to process any feedback you might have. HOW IT STARTED This adventure started as I was exploring a replacement for the docker tooling on my local machine, which led me to the tooling. A fine replacement, see my other articles on that exploration, but then I got to looking at how could we showcase our development projects and tooling using a browser only? Enter . Feel free to of this offering on their site, no need for me to determine for you if this is the right fit. I'm interested in Java development and wanted to test this out against one of my simple process automation tooling projects, could I get this into the IDE, build it, and deploy it in their container infrastructure within the bounds of my account? THE DASHBOARD I've chosen to use the Google Chrome browser for all the articles in this series, but it should not really matter so feel free to use your favourite browser. After logging in to the site, you can view. It presents the view to get started and reminds you that you have not yet created your first container. When you create a container you are then staring your first development project, that's end-to-end based on language type selection which will generate a project in your IDE and link that directly to a container to be deployed when you are ready. Before we do that, let's explore what else is available for our use. Under the menu on the right you can select SHARED WITH ME, to see a listing that is currently empty. If you have others you work with, here is where you can share container projects with other developers and you'll find them listed for your access. Pair programming of the future, at the container level! The CONNECTIONS item in the menu allows you to connect to SSH or FTP servers that might be hosing files, products, or projects that you want to be able to access from your IDE projects. Here is where you can add them to integrate them in the  IDE experience. ACCOUNT information includes the ability to connect to other developer services, view resource usage, and more. There is also the ability to create a TEAM ACCOUNT and put together your own CUSTOM STACKS for spinning up in a container where specific tooling versions might be required. Head back over to the CONTAINERS menu item and we'll get started in the next part of this series. So far you've taken a brief look at what this offering is, how to get it setup, and understand what you can do with it. Next up, part two takes us on a tour of setting up our very first container development project in the IDE.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/N5F8i1B0ELc" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/w_-D18LhPN8/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html</feedburner:origLink></entry><entry><title type="html">Introducing process operational monitoring for Kogito</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/TAhNJfc6NN8/introducing-process-operational-monitoring-for-kogito.html" /><author><name>Alessandro Costa</name></author><id>https://blog.kie.org/2021/09/introducing-process-operational-monitoring-for-kogito.html</id><updated>2021-09-28T10:00:00Z</updated><content type="html">Monitoring is a well known concept in Kogito: the was available since Kogito 0.11 through the Prometheus monitoring add-on. Today we announce that, starting from Kogito 1.11.0, this addon is enhanced to enable monitoring of processes. Unlike decisions, however, the feature is currently limited to operational metrics. The domain metrics section is a bit more complex to handle compared to decisions, so we decided to split the two and take some more time to properly design the latter while releasing the former to anyone who may benefit from it. KEY CONCEPTS The operational dashboard is intended to be used to check how your application responds quantitatively and to identify and react to possible malfunctions (e.g. slow responses, crash loops etc.). The addon currently exports one Grafana operational dashboard per process, which contains: * Total number of created instances * Total number of running instances * Total number of completed instances * Total number of instances that violated SLAs * Average process execution time, counted as the delta between the completion instant and the creation instant. There’s also a Global operational dashboard that contains the same graphs but with aggregated metrics for all the process types. You can use these default dashboards, or you can personalize them and use your custom dashboards. HOW TO USE IT First of all, the add-on must be imported in your Kogito project. The correct flavour (Quarkus or Spring Boot) must be chosen, depending on your underlying framework. Assuming that you have correctly imported the Kogito BOM to properly manage the versions, add the following dependency to your pom.xml: &lt;!-- Quarkus --&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;kogito-addons-quarkus-monitoring-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;kogito-addons-springboot-monitoring-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; At this point, once the application is packaged with mvn clean package the dashboards are generated under the path target/generated-resources/kogito/dashboards and the DevOps engineer can easily inject them during the deployment of the Grafana container. For the Grafana provisioning, we suggest having a look at . Example of process operational dashboard EXAMPLES Complete examples are available for both and . Check them out and go through the READMEs to get your hands on the addon in the real world. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/TAhNJfc6NN8" height="1" width="1" alt=""/&gt;</content><dc:creator>Alessandro Costa</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/introducing-process-operational-monitoring-for-kogito.html</feedburner:origLink></entry><entry><title type="html">a KIE JBang! catalog</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UWuhpX3Ns5E/a-kie-jbang-catalog.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2021/09/a-kie-jbang-catalog.html</id><updated>2021-09-28T09:53:34Z</updated><content type="html">In this episode, I want to share with you about an experimental catalog to quickly operate some KIE capabilities such as DMN and FEEL, directly on the Command Line! WHAT IS JBANG!? JBang! is a powerful command line and shell capability, allowing you to run jsh and Java source code as a script. JBang offers a great advantage with Java 8 compatibility and a very smart way to handle dependencies directly within the source of the scripts. You can read more about how JBang facilitates Developers, but also Students and Educators create, edit, and run self-contained source-only Java programs . You only need JBang to be installed on your system in order to follow the steps shown in the video and summarised in this post. DMN You can use the jbang dmn@kiegroup alias to evaluate a  using the Drools DMN Engine: The script takes as input a DMN mode file, and a DMN Context expressed as JSON. It produces as output a JSON of the evaluated DMN result context. As with most common command line utilities, you can issue --help to get usage help information: jbang dmn@kiegroup --help CONVERTER FOR EXCEL (.XLS/.XLSX) FILES CONTAINING DMN DECISION TABLES You can use the jbang xls2dmn@kiegroup alias to convert Excel (.xls/.xlsx) files containing  using the Drools DMN Engine experimental converter: For more details about the Converter and the conventions to be used in the Excel file, please reference the . FEEL You can use the jbang feel@kiegroup alias to evaluate a  using the Drools DMN Engine. This script takes as input a FEEL expression (as a string) and it produces a FEEL representation of the result of evaluating the expression. This jBang alias can be very handy when you want to quickly try out some FEEL expressions, using the command line for additional fun! CONCLUSIONS You can reference the video embedded with this post to get an overview of how to use this JBang! catalog. Don’t forget to checkout the for the full details. For more information on JBang, see: * * Try it out today! Go to: Don’t forget to let us know your feedback using the channels! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UWuhpX3Ns5E" height="1" width="1" alt=""/&gt;</content><dc:creator>Matteo Mortari</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/a-kie-jbang-catalog.html</feedburner:origLink></entry><entry><title>Set up mod_cluster for Red Hat JBoss Web Server with Ansible</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qtlE4FYvRA8/set-modcluster-red-hat-jboss-web-server-ansible" /><author><name>Romain Pelisse</name></author><id>6b5869c5-b1df-4808-9163-01748ffb84ff</id><updated>2021-09-28T07:00:00Z</updated><published>2021-09-28T07:00:00Z</published><summary type="html">&lt;p&gt;In the article &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;Automate Red Hat JBoss Web Server deployments with Ansible&lt;/a&gt;, we fully automated the setup of an &lt;a href="http://tomcat.apache.org/"&gt;Apache Tomcat server&lt;/a&gt; instance. In this follow-up, we'll further customize the behavior of the &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; web server. We will also use this opportunity to replace the Apache Tomcat distribution we deployed previously with &lt;a href="https://developers.redhat.com/products/webserver/overview"&gt;Red Hat JBoss Web Server&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Objectives&lt;/h2&gt; &lt;p&gt;We want to achieve two goals:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Replace Apache Tomcat with JBoss Web Server.&lt;/li&gt; &lt;li&gt;Activate the Java web server's &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_web_server/3/html/http_connectors_and_load_balancing_guide/sect-configure_load_balancing_using_apache_http_server_and_mod_cluster"&gt;&lt;code&gt;mod_cluster&lt;/code&gt; feature&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;As in the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous installment&lt;/a&gt;, we want to automate absolutely everything with &lt;a href="https://www.redhat.com/en/technologies/management/ansible"&gt;Ansible&lt;/a&gt;. This presents a slight challenge because we will have to retrieve the JBoss Web Server archive from the &lt;a href="https://access.redhat.com/"&gt;Red Hat Customer Portal&lt;/a&gt;—a protected resource.&lt;/p&gt; &lt;p&gt;As a reminder, our target environment is a &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux 8.4&lt;/a&gt; instance (so you can easily reproduce the demonstration):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# cat /etc/redhat-release Red Hat Enterprise Linux release 8.4 (Ootpa) # ansible --version ansible 2.9.22 config file = /etc/ansible/ansible.cfg configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python3.6/site-packages/ansible executable location = /usr/bin/ansible python version = 3.6.8 (default, Mar 18 2021, 08:58:41) [GCC 8.4.1 20200928 (Red Hat 8.4.1-1)] &lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The playbook might not work if you want to use a different Python version or target operating system.&lt;/p&gt; &lt;p&gt;Before we start, let's recap where the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous article&lt;/a&gt; left off by examining the complete playbook we ended up with:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- - name: "JBoss Web Server installation and configuration" hosts: "all" become: yes collections: – middleware_automation.jws tasks : vars: tomcat_version: 9.0.50 tomcat_base_url: https://archive.apache.org/dist/tomcat/tomcat-9/v tomcat_download_url: "{{ tomcat_base_url }}{{ tomcat_version }}/bin/apache-tomcat-{{tomcat_version}}.zip" tomcat_install_dir: /opt tomcat_zipfile: "{{tomcat_install_dir}}/tomcat.zip" tomcat_java_version: 1.8.0 tomcat_setup: true collections: - middleware_automation.jws roles: - jws pre_tasks: - name: "Download latest Apache Tomcat Zipfile from {{ tomcat_download_url }}." get_url: url: "{{ tomcat_download_url }}" dest: "{{ tomcat_zipfile }}" when: - tomcat_download_url is defined tasks: - name: " Checks that server is running" uri: url: "http://localhost:8080/" status_code: 404 return_content: no - name: "Deploy demo webapp" get_url: url: 'https://people.redhat.com/~rpelisse/info-1.0.war' dest: "{{ tomcat_home }}/webapps/info.war" notify: - Restart Tomcat service post_tasks: - name: "Sleep for {{ tomcat_sleep }} seconds to let Tomcat starts " wait_for: timeout: "{{ tomcat_sleep }}" - name: "Test application" get_url: url: "http://localhost:8080/info/" dest: /tmp/info.txt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An important reminder: The installation of Apache Tomcat is not described in this playbook, as this is entirely managed by the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. We only need to provide the path to the Apache Tomcat ZIP file, and logic within the JBoss Web Server collection of Ansible will execute the installation from there.&lt;/p&gt; &lt;h2&gt;Install JBoss Web Server with Ansible&lt;/h2&gt; &lt;p&gt;The first change we need to make is to remove the Apache Tomcat distribution details, which means deleting (or commenting out) the following variables: &lt;code&gt;tomcat_version&lt;/code&gt;, &lt;code&gt;tomcat_base_url&lt;/code&gt;, and &lt;code&gt;tomcat_download_url&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;With that complete, we now have to define new variables that will provide the required values for the playbook to download and install JBoss Web Server:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; vars: … tomcat_install_method: rhn_zipfiles tomcat_zipfile: "{{ tomcat_install_dir }}/jws.zip" tomcat_home: "{{ tomcat_install_dir }}/jws-5.4/tomcat"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We also can remove the entire &lt;code&gt;pre_tasks&lt;/code&gt; section, as it was dedicated to the download of the Apache Tomcat archive that is no longer needed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; pre_tasks: - name: "Download latest Apache Tomcat Zipfile from {{ tomcat_download_url }}." get_url: url: "{{ tomcat_download_url }}" dest: "{{ tomcat_zipfile }}" when: - tomcat_download_url is defined&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This new configuration will alter (at runtime) the behavior of the Ansible collection &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;&lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. As you may recall from the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous article&lt;/a&gt;, this collection has a dependency on another collection, &lt;a href="https://github.com/ansible-middleware/redhat-csp-download"&gt;&lt;code&gt;middleware_automation.redhat_csp_download&lt;/code&gt;&lt;/a&gt;, which—as the name suggests—downloads the required artifacts from the &lt;a href="https://access.redhat.com/"&gt;Red Hat Customer Portal&lt;/a&gt;. This dependency was not used in the previous article, but the changes to the variables will now activate it.&lt;/p&gt; &lt;p&gt;However, for this portion of the JBoss Web Server collection to run properly, we need to modify the playbook to reference the role name explicitly:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;collections: - middleware_automation.redhat_csp_download roles: - redhat_csp_download …&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To download the appropriate archive from the &lt;a href="https://access.redhat.com/"&gt;Red Hat customer portal&lt;/a&gt;, Ansible will need to authenticate, so we have to provide the proper credentials. We want to avoid specifying the connection details inside the main playbook, like other variables. So, we will use a separate file, called &lt;code&gt;credentials.yml&lt;/code&gt;, to specify them:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- rhn_username: username@redhat.com rhn_password: '&lt;password&gt;'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, we just need to have Ansible load those variables at execution time by specifying the file location as an additional variable:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-playbook -i inventory -e @credentials.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that everything is in place, the next time Ansible runs, the execution will connect to the &lt;a href="https://access.redhat.com/"&gt;Red Hat customer portal&lt;/a&gt;, download the archive, and install JBoss Web Server.&lt;/p&gt; &lt;h2&gt;Activate mod_cluster&lt;/h2&gt; &lt;p&gt;One of the nice added values of the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt; is the support for setting up &lt;code&gt;mod_cluster&lt;/code&gt;, a rather advanced functionality of the Java web server. By specifying a few extra variables, Ansible can configure and activate this feature.&lt;/p&gt; &lt;p&gt;For those not familiar with &lt;code&gt;mod_cluster&lt;/code&gt;, let us briefly summarize the capability of this tool. &lt;a href="https://modcluster.io/"&gt;&lt;code&gt;mod_cluster&lt;/code&gt;&lt;/a&gt; is an intelligent load balancer that uses a communication channel to forward requests from the load balancer to one of a set of application server nodes. The beauty of this protocol is that most of the setup is fully dynamic. We just need to provide some basic information to JBoss Web Server for the server to connect to the httpd instance and register its services (deployed applications, address and port, etc.).&lt;/p&gt; &lt;p&gt;How can we achieve this? By adding just three variables to the playbook: The listening port for &lt;code&gt;modcluster&lt;/code&gt; (&lt;code&gt;6666&lt;/code&gt;), the IP address of the httpd server to connect to, and the listening port for the &lt;code&gt;modcluster&lt;/code&gt; service on the JBoss Web Server side. See the following code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;vars : ... override_tomcat_modcluster_enable: yes override_tomcat_modcluster_ip: httpd.example.com override_tomcat_modcluster_port: 6666 override_tomcat_modcluster_listen_port: 6666&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Okay, we need a fourth variable to enable the feature within the collection, but that’s specific to the &lt;code&gt;automation_middleware.jws&lt;/code&gt; collection, not &lt;code&gt;mod_cluster&lt;/code&gt;.)&lt;/p&gt; &lt;p&gt;If we execute the playbook again, we can see that the &lt;code&gt;server.xml&lt;/code&gt; file is updated, which triggers a restart of the JBoss Web Server systemd service. This ensures the new settings are taken into account and activates the &lt;code&gt;mod_cluster&lt;/code&gt; functionality:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;... TASK [jws : Deploy custom configuration file from {{ item.template }}] *************************************************************************************** Friday 27 August 2021 05:53:26 -0400 (0:00:02.095) 0:00:38.688 ********* changed: [localhost] =&gt; (item={'template': 'templates/server.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/server.xml'}) ok: [localhost] =&gt; (item={'template': 'templates/web.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/web.xml'}) ok: [localhost] =&gt; (item={'template': 'templates/context.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/context.xml'}) TASK [jws : Remove app: {{ item }}] ************************************************************************************************************************** Friday 27 August 2021 05:53:28 -0400 (0:00:02.430) 0:00:41.118 ********* ok: [localhost] =&gt; (item=docs) ok: [localhost] =&gt; (item=ROOT) ok: [localhost] =&gt; (item=examples) TASK [jws : Copy tomcat vault file from control node to remote] ********************************************************************************************** Friday 27 August 2021 05:53:29 -0400 (0:00:01.142) 0:00:42.261 ********* skipping: [localhost] TASK [jws : Initialize tomcat vault] ************************************************************************************************************************* Friday 27 August 2021 05:53:30 -0400 (0:00:00.076) 0:00:42.337 ********* skipping: [localhost] RUNNING HANDLER [jws : Restart Tomcat service] *************************************************************************************************************** Friday 27 August 2021 05:53:30 -0400 (0:00:00.066) 0:00:42.404 ********* changed: [localhost] ... &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Customize the server.xml&lt;/h2&gt; &lt;p&gt;Quite often, the administrator of the JBoss Web Server (or Apache Tomcat) deployment will require fine-tuning of the &lt;code&gt;server.xml&lt;/code&gt; file. Up until this point, we have simply relied on the one generated automatically by the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. Indeed, it comes with its own templates that already allow transparent usage of a few complex features of the server (like &lt;code&gt;mod_cluster&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;While convenient, this approach cannot support all the possible configurations and implementation of the Java web server. This is why the collection also allows users to override the definition of this template in order to provide one of their own.&lt;/p&gt; &lt;p&gt;However, there is a (small) catch. If you have already activated some features (like &lt;code&gt;mod_cluster&lt;/code&gt;) with the help of the template supplied by the collection, those need to remain properly set up. It's easiest to use the &lt;code&gt;server.xml&lt;/code&gt; file from the collection as a base for the new template:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cp ~/.ansible/collections/ansible_collections/middleware_automation/jws/role/jws/templates/server.xml.j2 templates/server.xml.j2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With the custom template file in place, all that remains is to specify the &lt;code&gt;override_tomcat_conf_server&lt;/code&gt; variable so that the &lt;code&gt;automate_middleware.jws&lt;/code&gt; collection uses the new template file instead of the default:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;vars: … override_tomcat_conf_server: templates/server.xml.j2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That’s it! Just for the sake of completeness, the following is a bare-minimum template that you can use to build upon:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;Server port="{{ tomcat.shutdown.port }}" shutdown="SHUTDOWN"&gt; {% if tomcat.mod_cluster.enable %} &lt;Listener className="org.jboss.modcluster.container.catalina.standalone.ModClusterListener" connectorPort="{{ override_tomcat_modcluster_port }}" advertise="false" stickySession="true" stickySessionForce="false" stickySessionRemove="true" proxyList='{{ tomcat.mod_cluster.ip }}:{{ tomcat.mod_cluster.port }}'/&gt; {% endif %} &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector executor="tomcatThreadPool" port="{{ tomcat.listen.http.port }}" protocol="HTTP/1.1" allowTrace="false" {% if tomcat.listen.http.bind_address is defined %} address="{{ tomcat.listen.http.bind_address }}" {% endif %} connectionTimeout="20000" xpoweredBy="false" server="My Server" clientAuth="true" maxHttpHeaderSize="8192" redirectPort="{{ tomcat.listen.https.port }}"/&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;As a brief recap, this article demonstrated how to:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Use JBoss Web Server instead of the Apache Tomcat distribution.&lt;/li&gt; &lt;li&gt;Activate its &lt;code&gt;mod_cluster&lt;/code&gt; features and customizing the &lt;code&gt;server.xml&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Fully automate deployment and configuration using Ansible.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;It's noteworthy that no extra Ansible tasks have been added to the playbook. All we had to do was modify a few configuration variables—the &lt;code&gt;middleware_automation.jws&lt;/code&gt; collection did all of the automation heavy lifting. Pretty neat, isn’t it?&lt;/p&gt; &lt;p&gt;Thanks to this JBoss Web Server Ansible collection, managing JBoss Web Server (or Apache Tomcat) within an Ansible playbook is as easy and lightweight as it is with other resources, such as Nginx or firewalld. In short, the Java web server is now a first-class citizen inside the Ansible ecosystem.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/28/set-modcluster-red-hat-jboss-web-server-ansible" title="Set up mod_cluster for Red Hat JBoss Web Server with Ansible"&gt;Set up mod_cluster for Red Hat JBoss Web Server with Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qtlE4FYvRA8" height="1" width="1" alt=""/&gt;</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2021-09-28T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/28/set-modcluster-red-hat-jboss-web-server-ansible</feedburner:origLink></entry><entry><title type="html">Developing business processes more efficiently with Runtime Tools Quarkus extension – Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fJvPMsppnLE/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html" /><author><name>Paulo Martins</name></author><id>http://feeds.athico.com/~r/droolsatom/~3/fOftDz9KwZc/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html</id><updated>2021-09-28T01:52:11Z</updated><content type="html">This the first of a series of posts presenting our new Runtime Tools Quarkus extension, which brings the main features of both Management and Task consoles to the development environment in a much easier way to set up. HISTORY In the past, to use features like process instances list, jobs management and task inbox locally, it was necessary to set up both Management and Task consoles. This requires a full environment filled with external services, similar to what you would need in production. In the first release of this extension, it still requires some services, but we are removing the need for them step by step, until the extension is able to run without depending on them. INSTALLATION To install the extension, you just need to add it as a dependency of your project: &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;runtime-tools-quarkus-extension&lt;/artifactId&gt; &lt;version&gt;1.11.0.Final&lt;/version&gt; &lt;/dependency&gt; And also add some properties to your project src/main/resources/application.properties file: # Data-index service URL org.kie.kogito.runtime.tools.quarkus.extension.runtime.dataindex.DataIndexClient/mp-rest/url=http://localhost:8180 # Mocked users and groups for the task inbox screen quarkus.kogito-runtime-tools.users=jdoe,admin,user quarkus.kogito-runtime-tools.users.jdoe.groups=admin quarkus.kogito-runtime-tools.users.admin.groups=admin quarkus.kogito-runtime-tools.users.user.groups=user As mentioned before, this release still needs a few external services to function properly: Data-index, Jobs service and Kafka. EXECUTION To try the extension out, we will use the in the repository. There you can also find a comprehensive README on how to run the example and run a process. The following steps will run all external services needed and also the consoles, if you want to try them out as well: 1. Clone repository git clone https://github.com/kiegroup/kogito-examples 2. Build the example cd process-usertasks-timer-quarkus-with-console mvn clean install -DskipTests 3. Run Docker images cd docker-compose ./startServices.sh 4. Start runtimes cd process-usertasks-timer-quarkus-with-console mvn clean compile quarkus:dev Once this is executed, you can access the Quarkus Dev UI in the browser: WALK-THROUGH Once you open de Quarkus Dev UI, you will see something like this: At the top-right corner, you can see the card of our extension, Kogito Runtime Tools. There you can check the counts for process instances, tasks and jobs, and also enter the extension by clicking in one of them: Now let’s start a new process instance by making the following request: curl -H "Content-Type: application/json" -H "Accept: application/json" -X POST http://localhost:8080/hiring -d @- &lt;&lt; EOF { "candidate": { "name": "Harry Potter", "email": "harrypotter@example.com", "salary": 30000, "skills": "Java, Kogito" } } EOF Now if we refresh the list we can see our new process instance: And if we click in the instance, we can see its details: As you can see in the diagram in the process details, this instance is currently waiting for the IT Interview user task to be completed. If we go to the tasks list using the left menu, we can see it: And when we click in its name, we can complete the task: Once the user task is completed, the process instance will finish, and you can verify that by going back to the process instance details screen. NEXT STEPS In the next releases, we are planning to add new features and capabilities that will improve the extension experience. Here are some of them: * Embedded in-memory data-index One of our goals is to remove all the need for external services when using the extension. The first of those will be the data-index. * Process list and start As you saw during the walk-through, a manual request was made to start a new process instance, because currently it is not possible to start them using the UI. We plan to add a process list screen, where it will be possible to see the processes available at runtime and start them, passing the needed information. * Custom task forms In our current distributions, user tasks forms are automatically generated based on its schema. With this feature, we plan to allow developers to make custom forms using React or HTML and use them instead of the generated ones. -------------------------------------------------------------------------------- Stay tuned, this is the first part of a series of posts that we will be making along with new releases of the extension. We hope these new features will help make the development of business processes easier and more powerful. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fJvPMsppnLE" height="1" width="1" alt=""/&gt;</content><dc:creator>Paulo Martins</dc:creator><feedburner:origLink>http://feeds.athico.com/~r/droolsatom/~3/fOftDz9KwZc/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html</feedburner:origLink></entry><entry><title type="html">Handling Effective Date and Expiry Date with DMN Decisions</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cICXoGpO-pA/handling-effective-date-and-expiry-date-with-dmn-decisions.html" /><author><name>Sadhana Nandakumar</name></author><id>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</id><updated>2021-09-27T14:04:56Z</updated><content type="html">DMN is a modeling language and notation for the precise specification of business decisions. DMN is easily readable by the different types of people involved in decision management. supports the DMN open standards.  Handling effective date and expiry date of decisions is a common requirement across businesses. While it is entirely possible to handle the validity of decisions with different versions of the decision model, oftentimes there is a requirement to add variation at an individual decision node.  In this article, we will show how to achieve that with a practical example. Let us assume that we have a Card Approval Decision as shown below As you can see, we are calculating the Card Score based on Annual Income and Assets. This then determines if an Automatic Approval can be performed.  The Standard card score decision is expressed as a Decision Table: Let us say we now want a new condition for row 1, “When Annual Income &lt; 50 and Assets &lt; 100” starting with a specific date. Red Hat Process Automation Manager supports built-in functions to make this possible. today()Current Datenow()Current Date Time Let us now modify this decision table to add the date expiry condition. Notice how we have added the date condition to the decision row to decide it should be fired.  Let us now run these changes using the . The DMN artifact from this example is available .  Notice that since the effective date for Condition “When Annual Income &lt; 50 and Assets &lt; 100” matches the first row, the card Score evaluates to 312. Let us now change the rule to be effective from the beginning of this year and see what happens. You can now see that the rule matched the second row based on the date condition. Another way to define date validity is by defining it as a decision node so that one or more decisions can make use of it, it also allows you to make sure the logic is confined to one place. We will now use a combination of the built in date functions(today()/now()), as well as theto make this possible. Let us now create a new decision node called Date Validity.  Notice how we are using the temporal built-in function “after” in conjunction with “today” to determine validity. Now we will add this node to the existing DMN. The Standard card score now uses the Date Validity as defined by the decision node earlier. Let us now run this DMN. The DMN artifact from this example is available .  Since the effective date for the decision was next year, row 2 was fired yielding the card score result of 350. Test scenarios in Red Hat Process Automation Manager enable you to validate the functionality of business rules and business rule data before deploying them into a production environment. With a test scenario, you use data from your project to set given conditions and expected results based on one or more defined business rules. It is important to note that, while the test scenario by default maps the input data to the condition columns, it is possible to add a decision point as a condition column for better testability.  For instance, in the following scenario, you can see that Date Validity, which is a decision node in the DMN, is also pulled in as a condition column. If there needs to be a granular control of date checks, the decision node can be split up to reference date as an input column too. Now we can reference Today with different dates to test edge conditions seamlessly. References: – "Red Hat Decision Manager Supported Standards": * KIE Live 24: Squeezing the most out of DMN features, by . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cICXoGpO-pA" height="1" width="1" alt=""/&gt;</content><dc:creator>Sadhana Nandakumar</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</feedburner:origLink></entry><entry><title>Four reasons developers should use Ansible</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gV-jNmtU-0Y/four-reasons-developers-should-use-ansible" /><author><name>Don Schenck</name></author><id>34c398d7-20c8-478f-b887-418e086e3d55</id><updated>2021-09-27T07:00:00Z</updated><published>2021-09-27T07:00:00Z</published><summary type="html">&lt;p&gt;Ansible is described as "simple IT automation." It's an agentless tool, meaning you don't have to install anything on the systems you are controlling. With Ansible, you can install software, configure system settings and features, and do all the things system administrators do. You know, the "operations" side of the team.&lt;/p&gt; &lt;p&gt;So why should you, a developer, care? You should. Let me explain.&lt;/p&gt; &lt;h2&gt;What does Ansible do?&lt;/h2&gt; &lt;p&gt;To put it in the simplest terms, Ansible lets you do things remotely that you would otherwise do at the command line. Specifically, it's used to install software and change system settings. It puts a machine into the state in which you want it to remain and keeps it there.&lt;/p&gt; &lt;p&gt;For example, you can install (and maintain) a given version of a library on a select group of servers across your organization. You might want &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; 3.8 on all your &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; machines running in AWS. Ansible is perfect for that.&lt;/p&gt; &lt;p&gt;Maybe you want to make sure version 2 of your own software is installed on those servers. Again, Ansible does that.&lt;/p&gt; &lt;p&gt;You can even do nifty things like perform a rolling update across your virtual machines (VMs). Remove some of the servers from the load balancer pool, update to version 3 of your software (using our example), and return the servers to the load balancer pool. Then move on to the next batch of servers, and so on, until all of your servers are running version 3 of your application.&lt;/p&gt; &lt;h2&gt;How Ansible can help developers&lt;/h2&gt; &lt;p&gt;Ansible is a big deal for developers because you can easily configure and maintain machines with what Ansible calls "playbooks": easy-to-read, declarative statements that you can store in source control. Take a look at this example (copied from the &lt;a href="https://www.ansible.com/blog/getting-started-writing-your-first-playbook"&gt;Ansible Getting Started page&lt;/a&gt;) and you'll be able to mostly figure out what it does:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;--- - name: Install nginx hosts: host.name.ip become: true tasks: - name: Add epel-release repo yum: name: epel-release state: present - name: Install nginx yum: name: nginx state: present - name: Insert Index Page template: src: index.html dest: /usr/share/nginx/html/index.html - name: Start NGiNX service: name: nginx state: started&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I can think of four reasons why you, as a developer, should care about Ansible:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;You can use it to set up small environments.&lt;/li&gt; &lt;li&gt;You can use it to make sure the correct prerequisites are installed.&lt;/li&gt; &lt;li&gt;You can be a catalyst for real DevOps culture at work.&lt;/li&gt; &lt;li&gt;You can use it for yourself.&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;1: You can use Ansible to set up small environments&lt;/h3&gt; &lt;p&gt;Throughout my many years in enterprise software development, my colleagues and I often had the opportunity to carve out small networks of our own. We used these networks to install various packages and software, test different approaches, try new things... in short, play around.&lt;/p&gt; &lt;p&gt;Having Ansible on hand to create environments quickly is fantastic. It's often desirable to set things up, experiment, then tear everything down and start over. Nothing is more frustrating than deploying a solution and having it fail with the "But it runs on our machines" experience, only because an artifact on your machine wasn't included in the installation process. Ansible can solve that by easily enabling you to start from zero every time.&lt;/p&gt; &lt;p&gt;As a developer, I love the idea of completely starting over every time—as long as it is super easy. Thanks, Ansible.&lt;/p&gt; &lt;h3&gt;2: You can use Ansible to make sure the correct prerequisites are installed&lt;/h3&gt; &lt;p&gt;Sometimes breaking changes to libraries or runtimes (Python, anyone?) can, well, break your application. Because Ansible playbooks are easy to understand and change—it's YAML, after all—you can enforce the correct version of any library, runtime, software, etc. This relieves operations from this burden, which plays perfectly into my next point.&lt;/p&gt; &lt;h3&gt;3: You can be a catalyst for real DevOps culture at work&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; is a culture and set of behaviors. It's not a spreadsheet or a piece of software you install. It's developers and operations working together to automate all the things. Having &lt;a href="https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac"&gt;Infrastructure as Code&lt;/a&gt; is the basis. Allowing developers and operations to change that code, use version control, and trust one another—well, that's about as DevOps-y as you can get. The ability to pull down an Ansible playbook, run it, and test the results any time you want? That's huge. It is programming and system administration as one.&lt;/p&gt; &lt;h3&gt;4: You can use Ansible for yourself&lt;/h3&gt; &lt;p&gt;What if you were working on your laptop and you wanted to wipe it clean and start over? What if you could wipe it clean, pull a playbook from a network drive (or GitHub or a thumb drive or what-have-you), and use a tool to set up your machine?&lt;/p&gt; &lt;p&gt;With Ansible, you can do this over and over with the same results. You can repave your machine whenever you want without having to remember to run a script at the command line or install this and that.&lt;/p&gt; &lt;p&gt;In fact, as a developer, this might be your best use of Ansible and a great starting point for mastering it.&lt;/p&gt; &lt;h2&gt;Ops, I did it again&lt;/h2&gt; &lt;p&gt;So there it is. The old "DevOps" word again. We developers need to embrace it because it's not going away. Let's use this DevOps concept to everyone's advantage and promote cross-disciplinary skills, more Infrastructure as Code, and the ultimate goal: more stable systems. Something we all want.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible" title="Four reasons developers should use Ansible"&gt;Four reasons developers should use Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gV-jNmtU-0Y" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-09-27T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible</feedburner:origLink></entry><entry><title type="html">Beginners Guide to Installing Process Automation Tooling in a Local Container using Podman</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Rcwp8fHMwJo/beginners-guide-to-rhpam-local-conainter-podman.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/eaXnZhtViS0/beginners-guide-to-rhpam-local-conainter-podman.html</id><updated>2021-09-27T05:00:00Z</updated><content type="html">Recently the open source  announced that there was solid support for using its container tooling to replace docker on your local development machine. Ring in the joyous music and off we go to explore how we can get back to basics without the issues of licensing around the developer desktop container tooling. Note, the rest of this tutorial will be based on the current version of Podman at the time of publication, v3.3.1. The first thing you want to do is just install the Podman tooling, which is fairly painless using BREW: $ brew install podman Now you are ready to kick off the virtual machine with the proper settings to start doing something real, like adding developer process automation tooling to your local machine. You start by initialise and start the virtual machine to run Podman on: $ podman machine init --memory 6144 --disk-size 20 Extracting compressed file Image resized. If it's your first time doing this, an image will be downloaded first, but in this case a cached version of that image is just being unpacked and setup. Now it's time to start the virtual machine: $ podman machine start INFO[0000] waiting for clients... INFO[0000] listening tcp://0.0.0.0:7777 INFO[0000] new connection from to /var/folders/_y/1rjzwypx57sd677v9jzrr0nc0000gp/T/podman/qemu_podman-machine-default.sock Waiting for VM ... qemu-system-x86_64: warning: host doesn't support requested feature: CPUID.80000001H:ECX.svm [bit 2] Now once this completes, you're ready to take a swing at spinning up the developer process automation tooling by Red Hat. First we pull in this nice demo project for installing it locally or in a container: $ git clone https://gitlab.com/bpmworkshop/rhpam-install-demo.git Then go into the rhpam-install-demo directory and examine the instructions for using this with Podman to spin up the process automation developer tooling in a container. You will note that you need to head over to and obtain the files listed in the installs/README before you can continue.  Before you try to use Podman to build, pull, or run any images on your machine, verify that the virtual machine is running to support you: $ podman machine list NAME VM TYPE CREATED LAST UP podman-machine-default* qemu 9 minutes ago Currently running Once that's done, you can start from the root directory and build your first image: $ podman build -t rhpam-install:7.11 . ...CUT OUTPUT... STEP 24/26: USER 1000 --&gt; 2a682b0c5aa STEP 25/26: EXPOSE 9990 9999 8080 8001 --&gt; 6a1ed7c4d2e STEP 26/26: CMD ["/opt/jboss/rhpam/jboss-eap-7.3/bin/standalone.sh","-c","standalone.xml","-b", "0.0.0.0","-bmanagement","0.0.0.0"] COMMIT rhpam-install:7.11 --&gt; fbba2e41494 Successfully tagged localhost/rhpam-install:7.11 fbba2e4149409794a8c81f05c59f402e4ddca775dc07cbaeed3ae3bf0cf703b7 This will take some time to execute every line in the provided Dockerfile, so feel free to watch or explore that file until the build process is done. You can verify that you have a new image built: $ podman image list REPOSITORY TAG IMAGE ID CREATED SIZE localhost/rhpam-install 7.11 fbba2e414940 7 minutes ago 4.05 GB docker.io/jbossdemocentral/developer latest b73501ac39b1 5 years ago 514 MB You can see the base image is a customised developer image that we then use to build our rhpam-install image.  The next step is to run the image: $ podman run -dt -p 8080:8080 -p 9990:9990 rhpam-install 9bd0e70e58dd471a4ad17b87281c8bfe73a98e5a9bfc6cbd37fa98fb0198d1a0 This starts the image and spins up both Red Hat Enterprise Application Server and running inside of that the Red Hat Process Automation tooling. You can view this by looking up the container id, then viewing the log file to ensure the container startup is completed before using the tooling: $ podman container list CONTAINER ID IMAGE COMMAND CREATED 9bd0e70e58dd localhost/rhpam-install:7.11 /opt/jboss/rhpam/... 2 minutes ago $ podman logs 9bd0e70e58dd ... CUT OUTPUT OF DUMPED LOG FILE... 12:50:50,612 INFO [org.kie.workbench.common.screens.datasource.management.backend.DataSourceManagementBootstrap] (pool-30-thread-1) Initialize deployments task finished successfully. Note you can use the -f flag to attache the logs output to the console and watch the container start up. Now that it's been started successfully we can make use of the port mapping we did at podman run when we used the -p flag. Port 8080 from our localhost is now mapped through to the containers port.  You can verify this with: $ podman port 9bd0e70e58dd 8080/tcp -&gt; 0.0.0.0:8080 9990/tcp -&gt; 0.0.0.0:9990 Now you can access the process automation business central log in to access the tooling at: http://localhost:8080/business-central The login user: erics The password: redhatpam1! You will be presented with the business central dashboard and you are ready to start automating processes using this tooling in a container on your local machine.  If you need help getting started, try one of the !&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Rcwp8fHMwJo" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/eaXnZhtViS0/beginners-guide-to-rhpam-local-conainter-podman.html</feedburner:origLink></entry><entry><title type="html">Changes are coming to WildFly</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lEgx4-fm3Qg/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2021/09/27/WildFly-Changes/</id><updated>2021-09-27T00:00:00Z</updated><content type="html">As significant changes percolate through the enterprise Java ecosystem, particularly progress on Jakarta EE 10 and the move to the jakarta.* namespace for the EE APIs, changes are also going to be coming to WildFly. In this post I want to describe what I see happening over the next few WildFly releases, starting with the WildFly 25 release that will be out soon. SE 17 AND THE WILDFLY SECURITY LAYER This month’s GA release of the LTS release has highlighted the importance of WildFly being a good choice for those wanting to run applications on the latest SE. As a result, a key focus in WildFly 25 has been completing our migration away from the legacy security layer that dates back to JBoss AS and onto the -based introduced in WildFly 11. Using Elytron security has been our recommended approach for several years now, but since SE 17 does not provide packages that legacy security heavily relies upon, the time has come to complete the transition off of legacy security. We deprecated the use of legacy security long ago and in the WildFly 25 release we are removing support for it. As part of this change you will see a number of significant changes in WildFly 25: * Our standard configuration files no longer include legacy security realms. These are the 'security-realm' elements found under the 'management' element in a standalone.xml or host.xml file, administered via the CLI at '/core-service=management/security-realm=*' addresses. The xml parsers no longer support these elements and the management API no longer provides resources at these addresses. Elytron subsystem resources are now used. * Use of the Picketbox-based security vault is no longer supported. Elytron credential stores should be used instead. * The 'org.wildlfy.extension.picketlink' extension and the 'picketlink-federation' and 'picketlink-idm' subsystems it provided are no longer supported on servers not running in 'admin-only' mode. They can still be used on a WildFly 25 Domain Controller to allow it to manage hosts running earlier versions of WildFly. * The 'org.jboss.as.security' extension and the 'security' subsystem it provides are no longer part of our standard configuration files. By the time WildFly 25.0.0.Final is released our intent is that these will no longer be supported on servers not running in 'admin-only' mode. The extension and subystem can still be used on a WildFly 25 Domain Controller to allow it to manage hosts running earlier versions of WildFly. Note that the reason use of the legacy security and picketlink extensions is allowed on an 'admin-only' server is to allow a server with a configuration using those to boot so an administrator can then use the CLI to alter the server configuration to use Elytron. I very much encourage any of you still using legacy security in your configuration to start experimenting with WildFly 25, including with the WildFly 25 Beta1 release we . EE 10 AND THE JAKARTA.* NAMESPACE Work on is ramping up, with a rough estimate GA date at the end of . WildFly contributors are of course involved with EE 10, including back-to-the-early-JBoss-days veteran Scott Stark driving the release overall, Scott Marlow playing a key role on the TCK and WildFly contributors active on a number of specs. WildFly intends to shift its EE support in its main distribution to EE 10 when it’s available. The precise release when that will happen is as yet unknown, but WildFly 28 seems a reasonable candidate, as following our normal quarterly release cadence that would be the release in development when EE 10 is expected to go GA. The distribution of the server will shift toward EE 10 earlier than that. It currently targets EE 9.1 and has been an EE 9.1 compliant server since the 23.0.2 release. The primary purpose of WildFly Preview though is providing a tech preview look at what’s coming in future standard WildFly releases, and not so much things like strict EE compliance. So, as EE 10 components start to become available (even betas), if they work well in WildFly Preview we’ll start to integrate them in the WildFly Preview releases, even if that means we’re no longer EE 9.1 compliant. This may begin to happen with the WildFly Preview 26 release (expected in December) and almost certainly will in WildFly Preview 27. MOVING ON FROM JAKARTA EE 8 SUPPORT IN STANDARD WILDFLY By the time standard WildFly moves to EE 10 support, my expectation is the project will no longer produce feature releases that support Jakarta EE 8. As what we’ve done with WildFly Preview demonstrates, the WildFly architecture allows the project to support different variants that support different Jakarta EE versions, but I don’t believe the project will attempt to provide an EE 8 variant once the main distribution moves to EE 10. There are a number of reasons for this, all related to the effort involved: * The EE 10 APIs are going to differ from the EE 8 APIs in ways that go beyond the javax.* vs jakarta.* package name differences between EE 8 and EE 9. Where those differences affect the server integration of those specs, we’d need to provide separate integration logic for EE 8 vs EE 10. That is certainly technically possible, but shifting the focus of WildFly’s contributors to developing and maintaining separate integrations would impact their ability to drive other innovation in the server. * Similarly, as components we integrate absorb the jakarta namespace change and evolve in general, it is likely that their own APIs will evolve distinctly between their javax.* releases and their jakarta.* ones. This again would likely result in the need to develop and maintain separate integration logic. * Different component sets between two variants of WildFly mean the need to monitor more component for CVEs and critical bugs. * There is a lot of continuous integration testing that backs standard WildFly. Trying to test two different variants of standard WildFly, plus WildFly Preview, would put excessive strain on our CI infrastructure. WHEN WILL THIS TRANSITION HAPPEN? Honest answer: I’m not sure. But it’s possible even WildFly 26 at the end of this year could move from EE 8 to EE 9.1. And the chances are pretty good WildFly 27 will. What would be required for WildFly to move from EE 8 to EE 9.1? * We’d need to have native jakarta.* variants available in public maven repos of all components that use the EE APIs. WildFly Preview bytecode transforms components that use javax.* when it provisions a server, but for standard WildFly we would need to have components available from maven. We’re progressing toward achieving that, and there’s some possibility we’ll get there during the WildFly 26 development cycle. * We would need to be able to continue to be EE 9.1 compliant with those components. Why would WildFly move to EE 9.1, instead of waiting for EE 10? The WildFly developers have been reluctant to move the standard distribution to EE 9.1, because it has no added functionality vs EE 8, it just brings a migration cost. So why would we move to EE 9.1 instead of just using WildFly Preview until EE 10 is ready? Basically what would drive this would be differences in our EE 8 vs EE 9+ components that force the need for overly-costly-to-maintain-and-test differences in the relevant server integration logic. It’s possible this could occur during the WildFly 26 cycle, and the chances increase as we get to WildFly 27. My hope though is that we can avoid this and can provide EE 8 until our EE 10 support is ready. I will post more about this as work continues and the picture becomes clearer. SUPPORT FOR SE 8 WildFly has long supported running on SE 8, but I expect that to come to an end over the next few releases. EE 10 itself does not require its constituent APIs to support the SE 8 source or binary level, and it’s very likely that a number of EE APIs will require SE 11. That means once WildFly itself is an EE 10 server, we will require SE 11 or later. It’s also possible that we will make this transition earlier than that, particularly if one or more of our major components requires SE 11. It’s possible this could happen as soon as WildFly 26, but I doubt it and would very much want to avoid it. As work on 26 proceeds, I’ll be sure to communicate if things are happening that make a move off of SE 8 in WildFly 26 or 27 look likely. QUESTIONS? If you have questions or want to provide feedback, I encourage you to post on the , on the or in . Best regards, Brian&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lEgx4-fm3Qg" height="1" width="1" alt=""/&gt;</content><dc:creator>Brian Stansberry</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/09/27/WildFly-Changes/</feedburner:origLink></entry><entry><title>Containerized Python Flask development on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rtyk8BnVxa0/containerized-python-flask-development-environment-red-hat-codeready-workspaces" /><author><name>Shane Boulden</name></author><id>7ca79c17-de44-4c55-82fc-b85c38f78bcf</id><updated>2021-09-24T07:00:00Z</updated><published>2021-09-24T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview/"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; provides developers with containerized development environments hosted on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. Having a hosted development environment that's pre-built for your chosen stack and customized for your project makes onboarding new developers easier because everything they need is already running in a containerized workspace.&lt;/p&gt; &lt;p&gt;In this article, I'll show you how to use CodeReady Workspaces to get up and running quickly with a Flask-based &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; project. We'll set up the environment, make a few modifications to the application, then validate and verify the changes from within the containerized development environment.&lt;/p&gt; &lt;h2&gt;Updated for OpenShift 4&lt;/h2&gt; &lt;p&gt;To follow the example in this article, you'll need &lt;a href="https://developers.redhat.com/products/openshift/whats-new"&gt;OpenShift 4&lt;/a&gt;. You can use &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; on your Windows, macOS, or Linux laptop. Or, you can access a hosted Red Hat OpenShift Container Platform cluster for free in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Let's get started!&lt;/p&gt; &lt;h2&gt;Deploying CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;CodeReady Workspaces uses a Kubernetes Operator for deployment. A &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt; is basically a method of packaging, deploying, and managing a Kubernetes application.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you'd like to know more about the Operator Framework, see the awesome write-up by Brandon Philips on the &lt;a href="https://blog.openshift.com/introducing-the-operator-framework/"&gt;OpenShift blog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;CodeReady Workspaces is available through the OpenShift Operator Hub. Once you've found the CodeReady Workspaces Operator, install it as shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Installing the CodeReady Workspaces Operator." data-entity-type="file" data-entity-uuid="c2996aee-63a9-46d6-ba45-04b249c7c8b3" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2015-36-29.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Installing the CodeReady Workspaces Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select the defaults for this installation, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Default configuration for the CodeReady Workspaces Operator." data-entity-type="file" data-entity-uuid="a42b9085-3e19-46fd-a906-ab42d25ea5aa" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2015-36-41.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: The default configuration for the CodeReady Workspaces Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When the CodeReady Workspaces Operator is installed and ready to use, you'll see a notification like the one in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The CodeReady Workspaces Operator has been successfully installed." data-entity-type="file" data-entity-uuid="3b0e1451-8f6e-4a1f-b2a7-0ff7af0fe103" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-33-55.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: The operator has been successfully installed.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the operator is installed, you can access it under &lt;strong&gt;Installed Operators&lt;/strong&gt;. From here, select &lt;strong&gt;Create Instance&lt;/strong&gt; next to the &lt;strong&gt;CodeReady Workspaces Cluster&lt;/strong&gt; custom resource. Accept all the defaults, and select &lt;strong&gt;Create&lt;/strong&gt;, as shown in Figure 4.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Creating an OpenShift cluster in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="254f113b-edd8-4131-9bea-b55b2c001964" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-34-13.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 4: Creating a CodeReady Workspaces cluster with the operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The operator will now take over and create all of the components for your CodeReady Workspaces cluster. Once it's finished you'll see a couple of new routes, as shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="New routes in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="29d05a2f-d016-4e7d-927d-396aa88b49a9" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-36-49.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 5: New routes for CodeReady Workspaces created by the operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Navigate to the CodeReady route, follow the prompts to authenticate with single sign-on (SSO), and you'll be directed to the dashboard shown in Figure 6.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The CodeReady Workspaces dashboard." data-entity-type="file" data-entity-uuid="f5f129fb-69a8-42dd-a377-ef29af175afb" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-56-18.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 6: The CodeReady Workspaces dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Next, we'll set up the Flask workspace for our Python project.&lt;/p&gt; &lt;h2&gt;Creating the Flask workspace&lt;/h2&gt; &lt;p&gt;We're going to use a &lt;a href="https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified"&gt;devfile&lt;/a&gt; to create the workspace for our application. A &lt;em&gt;devfile&lt;/em&gt; is a way of codifying a containerized workspace, and is usually stored with the application source so that it can be version-controlled alongside the application. Here is the &lt;a href="https://github.com/shaneboulden/flask-questions-app/blob/main/devfile.yml"&gt;devfile for the example Flask application&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;apiVersion: 1.0.0 metadata: generateName: flask- projects: - name: flask-app source: type: git location: "https://github.com/shaneboulden/flask-questions-app" components: - type: chePlugin id: ms-python/python/latest - type: dockerimage alias: python image: quay.io/eclipse/che-python-3.8:next memoryLimit: 512Mi mountSources: true env: - name: FLASK_SECRET value: 'you-will-never-guess' endpoints: - name: websocket-forward port: 8080 attributes: protocol: http secure: 'false' public: 'true' discoverable: 'false' commands: - name: run actions: - type: exec component: python command: '${HOME}/.local/bin/gunicorn wsgi:application -b 0.0.0.0:8080' workdir: '${CHE_PROJECTS_ROOT}/flask-app' - name: install actions: - type: exec component: python command: 'pip3 install -r requirements.txt' workdir: '${CHE_PROJECTS_ROOT}/flask-app'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Let's break down this devfile:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;New workspaces will be generated with a name starting with &lt;code&gt;flask-&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;The source code for this project is hosted at &lt;a href="https://github.com/shaneboulden/flask-questions-app"&gt;https://github.com/shaneboulden/flask-questions-app&lt;/a&gt; and will be cloned into the workspace.&lt;/li&gt; &lt;li&gt;We're using a base Python environment from the &lt;a href="https://www.eclipse.org/che/docs/che-7/hosted-che/hosted-che/"&gt;Eclipse Che&lt;/a&gt; project hosted at Quay.io.&lt;/li&gt; &lt;li&gt;We've limited workspaces created from this devfile to 512 MB of memory.&lt;/li&gt; &lt;li&gt;We've created an environment variable for the Flask cross-site request forgery (CSRF) secret, ensuring the secret isn't stored in the source.&lt;/li&gt; &lt;li&gt;We've created an endpoint for the web server used in development. This will allow us to test out the Flask app inside the containerized workspace.&lt;/li&gt; &lt;li&gt;We've created two commands, &lt;code&gt;install&lt;/code&gt; and &lt;code&gt;run&lt;/code&gt;. We'll use these to easily install the application dependencies, run the web server, and view our changes to the Flask application.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Select &lt;strong&gt;Custom Workspace&lt;/strong&gt; from the CodeReady Workspaces dashboard. Then, in the &lt;strong&gt;Devfile&lt;/strong&gt; section of the following form specify the devfile URL (Figure 7) :&lt;/p&gt; &lt;p&gt;&lt;code&gt;https://raw.githubusercontent.com/shaneboulden/flask-questions-app/main/devfile.yml &lt;/code&gt;&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Specify the devfile URL in the custom workspace configuration." data-entity-type="file" data-entity-uuid="784f3852-2450-4d7d-8ea8-5c9aaec7de79" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2016-57-53.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 7: Specify the devfile URL in the custom workspace configuration.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select &lt;strong&gt;Load Devfile—&gt;Create &amp; Open&lt;/strong&gt; to start creating the custom workspace. When it's complete you'll see the new workspace with the source code explorer open, as shown in Figure 8.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The new custom workspace." data-entity-type="file" data-entity-uuid="e7878db2-dbe4-4206-9498-5bd96971317a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2017-00-26.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 8: The new custom workspace for Flask.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Exploring the Flask workspace&lt;/h2&gt; &lt;p&gt;Now that our workspace is created, let's explore some of the configuration we've created. Select the power cord on the right to see the endpoints (Figure 9).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Viewing the devfile endpoints." data-entity-type="file" data-entity-uuid="49c55275-1b81-455d-950d-d16ee1156392" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2017-00-39.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 9: Viewing the devfile endpoints.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;There's a single endpoint created here for port 8080. When we run the web server inside the workspace, this endpoint will be activated so we can view the application.&lt;/p&gt; &lt;p&gt;We also have a couple of commands created by the devfile. If you select &lt;strong&gt;Terminal—&gt;Run task&lt;/strong&gt;, you'll see the commands shown in Figure 10.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="A list of available tasks in the devfile." data-entity-type="file" data-entity-uuid="612aabf2-27df-449f-9104-65f1fe32dd0a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-37-33.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 10: A list of runnable tasks.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Let's run the &lt;strong&gt;Install&lt;/strong&gt; first. When you execute the task, you should see a terminal output window opened, as shown in Figure 11.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Output of running the Install task." data-entity-type="file" data-entity-uuid="4fc4e9f2-adc1-488e-b7db-9b3260d25d82" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-37-50.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 11: Run the Install task.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Our dependencies are now installed, so let's run the application. Select &lt;strong&gt;Terminal—&gt;Run Task&lt;/strong&gt; and the &lt;strong&gt;run&lt;/strong&gt; command. You'll see the web server open up in a new terminal output in a new window. CodeReady Workspaces will also detect that the endpoint is now available, and prompt you to either open it in a new tab or a preview within the workspace. Figure 12 shows the endpoint prompt.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Open or preview the endpoint in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="93528f16-aa3d-4962-895b-2dd7470d5575" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-40-11.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 12: Open or preview the endpoint in CodeReady Workspaces.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select either option to view the Flask application, as shown in Figure 13.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="View the Flask web application." data-entity-type="file" data-entity-uuid="321513a5-3585-474b-b3f4-b3aedfbf717a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-40-20.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 13: Viewing the Flask web application.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Updating the Flask application&lt;/h2&gt; &lt;p&gt;Everything's looking good! We've got a containerized workspace created for our application development environment, and a couple of codified commands and endpoints we can use to quickly prepare the environment and get our application running.&lt;/p&gt; &lt;p&gt;Let's make a change and see how it is reflected in the workspace. Expand the source code explorer and find the &lt;code&gt;index.html&lt;/code&gt; file, as shown in Figure 14.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The index template in code explorer." data-entity-type="file" data-entity-uuid="434c5d23-288f-4fc2-ab5b-c5d84752c010" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-43-48.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 14: The index template in code explorer.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Change the line:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;h1&gt;Ask us anything.&lt;/h1&gt;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;To read:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;h1&gt;Welcome.&lt;/h1&gt;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Stop the web server (press &lt;strong&gt;Ctrl-C&lt;/strong&gt; in the &lt;strong&gt;Run&lt;/strong&gt; window), and select &lt;strong&gt;Terminal—&gt;Run last task&lt;/strong&gt; to restart the web server. Alternatively, you can press &lt;strong&gt;Ctrl-Shift-K&lt;/strong&gt;. Open the preview or new tab again, and verify the page now contains the new greeting shown in Figure 15.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Modified code" data-entity-type="file" data-entity-uuid="7bd9b10c-3e81-4f82-a727-cad4cf51b982" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-48-15.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 15: Verify the update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Do more with Python, Flask, and OpenShift&lt;/h2&gt; &lt;p&gt;We now have a containerized development environment for our Flask application that's hosted on OpenShift, and we can access it anytime. When new developers join the team, we can simply allow them to load the workspace with the devfile and quickly instantiate their own development environment. All the changes to the devfile are version controlled with the application source, so we can keep our development environment in lockstep with the Flask application.&lt;/p&gt; &lt;p&gt;If you want to take what you've learned in this article a step further, you can create a Python development environment for a machine learning workflow. Brian Nguyen's &lt;a href="https://cloud.redhat.com/blog/configure-code-ready-workspace-for-developing-machine-learning-workflow"&gt;excellent article&lt;/a&gt; will get you started. Also, see &lt;a href="https://developers.redhat.com/blog/2021/04/14/using-a-custom-devfile-registry-and-c-with-red-hat-codeready-workspaces"&gt;Using a custom devfile registry and C++ with Red Hat CodeReady Workspaces&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2020/11/16/devfiles-and-kubernetes-cluster-support-in-openshift-connector-0-2-0-extension-for-vs-code"&gt;Devfiles and Kubernetes cluster support in OpenShift Connector 0.2.0 extension for VS Code&lt;/a&gt; for more about the technologies used in the example. Visit the &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;CodeReady Workspaces landing page&lt;/a&gt; for more about CodeReady Workspaces.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/blog/2019/02/18/containerized-python-flask-development-environment-red-hat-codeready-workspaces" title="Containerized Python Flask development on Red Hat OpenShift"&gt;Containerized Python Flask development on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rtyk8BnVxa0" height="1" width="1" alt=""/&gt;</summary><dc:creator>Shane Boulden</dc:creator><dc:date>2021-09-24T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/18/containerized-python-flask-development-environment-red-hat-codeready-workspaces</feedburner:origLink></entry></feed>
